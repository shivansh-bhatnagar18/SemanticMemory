{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wjtpk5I4rcgG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import spearmanr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HALModel:\n",
        "    def __init__(self, window_size=2):\n",
        "        self.window_size = window_size\n",
        "        self.word_index = {}\n",
        "        self.context_index = {}\n",
        "        self.co_occurrence_matrix = None\n",
        "\n",
        "    def build_co_occurrence_matrix(self, sentences):\n",
        "        # Build word and context indices\n",
        "        for sentence in sentences:\n",
        "            for word in sentence:\n",
        "                if word not in self.word_index:\n",
        "                    self.word_index[word] = len(self.word_index)\n",
        "                for context_word in sentence:\n",
        "                    if context_word != word:\n",
        "                        if context_word not in self.context_index:\n",
        "                            self.context_index[context_word] = len(self.context_index)\n",
        "\n",
        "        # Initialize the co-occurrence matrix\n",
        "        self.co_occurrence_matrix = np.zeros((len(self.word_index), len(self.context_index)))\n",
        "\n",
        "        # Fill the co-occurrence matrix based on word-context pairs\n",
        "        for sentence in sentences:\n",
        "            for i, target_word in enumerate(sentence):\n",
        "                start = max(0, i - self.window_size)\n",
        "                end = min(len(sentence), i + self.window_size + 1)\n",
        "                context_words = sentence[start:i] + sentence[i + 1:end]\n",
        "                target_index = self.word_index.get(target_word, None)\n",
        "                if target_index is not None:\n",
        "                    for context_word in context_words:\n",
        "                        context_index = self.context_index.get(context_word, None)\n",
        "                        if context_index is not None:\n",
        "                            self.co_occurrence_matrix[target_index, context_index] += 1\n",
        "\n",
        "    def train(self, sentences):\n",
        "        self.build_co_occurrence_matrix(sentences)\n",
        "\n",
        "    def similarity(self, word1, word2):\n",
        "        if self.co_occurrence_matrix is None:\n",
        "            raise ValueError(\"Model has not been trained. Call train() first.\")\n",
        "\n",
        "        # Check if both words are in the vocabulary\n",
        "        if word1 not in self.word_index or word2 not in self.word_index:\n",
        "            # Handle the case where one or both words are not in the vocabulary\n",
        "            return 0.0  # You can adjust this default value as needed\n",
        "\n",
        "        index1, index2 = self.word_index[word1], self.word_index[word2]\n",
        "        vector1 = self.co_occurrence_matrix[index1, :]\n",
        "        vector2 = self.co_occurrence_matrix[index2, :]\n",
        "        similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
        "        return similarity"
      ],
      "metadata": {
        "id": "cbkiY6Y8rleD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_similarity(model, word_pairs, human_scores):\n",
        "    predicted_scores = [model.similarity(word1, word2) for word1, word2 in word_pairs]\n",
        "    spearman_corr, _ = spearmanr(predicted_scores, human_scores)\n",
        "    return spearman_corr"
      ],
      "metadata": {
        "id": "8JurNLzernp7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_cross_validation(model, sentences, word_pairs, human_scores, k=10):\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    spearman_correlations = []\n",
        "\n",
        "    for fold, (train_indices, val_indices) in enumerate(kf.split(sentences)):\n",
        "        print(f\"\\nFold {fold + 1}\")\n",
        "\n",
        "        # Split the data into training and validation sets\n",
        "        train_sentences = [sentences[i] for i in train_indices]\n",
        "        val_sentences = [sentences[i] for i in val_indices]\n",
        "\n",
        "        # Train the HAL model on the training set\n",
        "        model.train(train_sentences)\n",
        "\n",
        "        # Evaluate the model on the validation set\n",
        "        spearman_corr = evaluate_similarity(model, word_pairs, human_scores)\n",
        "        print(f\"Spearman Correlation: {spearman_corr:.4f}\")\n",
        "\n",
        "        # Append the correlation for this fold to the list\n",
        "        spearman_correlations.append(spearman_corr)\n",
        "\n",
        "    # Calculate and print the overall average correlation across all folds\n",
        "    overall_avg_corr = np.mean(spearman_correlations)\n",
        "    print(f\"\\nOverall Average Spearman Correlation: {overall_avg_corr:.4f}\")"
      ],
      "metadata": {
        "id": "3q-dSMn_ruVe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "\n",
        "lines = []\n",
        "with open('shakespeare.txt', 'r') as f:\n",
        "    for l in f:\n",
        "        lines.append(l)\n",
        "\n",
        "# remove new lines\n",
        "lines = [line.rstrip() for line in lines]\n",
        "# make all characters lower\n",
        "lines = [line.lower() for line in lines]\n",
        "# remove punctuations from each line\n",
        "lines = [line.translate(str.maketrans('', '', string.punctuation)) for line in lines]\n",
        "# tokenize\n",
        "lines = [word_tokenize(line) for line in lines]\n",
        "print(lines[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POmFHg5Fr0Lm",
        "outputId": "fba10c5b-674f-4d36-cbdf-5f8e4e8d6290"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['act', 'i'], ['scene', 'i', 'london', 'the', 'palace'], ['enter', 'king', 'henry', 'lord', 'john', 'of', 'lancaster', 'the', 'earl', 'of', 'westmoreland', 'sir', 'walter', 'blunt', 'and', 'others'], ['so', 'shaken', 'as', 'we', 'are', 'so', 'wan', 'with', 'care'], ['find', 'we', 'a', 'time', 'for', 'frighted', 'peace', 'to', 'pant'], ['and', 'breathe', 'shortwinded', 'accents', 'of', 'new', 'broils'], ['to', 'be', 'commenced', 'in', 'strands', 'afar', 'remote'], ['no', 'more', 'the', 'thirsty', 'entrance', 'of', 'this', 'soil'], ['shall', 'daub', 'her', 'lips', 'with', 'her', 'own', 'childrens', 'blood'], ['nor', 'more', 'shall', 'trenching', 'war', 'channel', 'her', 'fields'], ['nor', 'bruise', 'her', 'flowerets', 'with', 'the', 'armed', 'hoofs'], ['of', 'hostile', 'paces', 'those', 'opposed', 'eyes'], ['which', 'like', 'the', 'meteors', 'of', 'a', 'troubled', 'heaven'], ['all', 'of', 'one', 'nature', 'of', 'one', 'substance', 'bred'], ['did', 'lately', 'meet', 'in', 'the', 'intestine', 'shock'], ['and', 'furious', 'close', 'of', 'civil', 'butchery'], ['shall', 'now', 'in', 'mutual', 'wellbeseeming', 'ranks'], ['march', 'all', 'one', 'way', 'and', 'be', 'no', 'more', 'opposed'], ['against', 'acquaintance', 'kindred', 'and', 'allies'], ['the', 'edge', 'of', 'war', 'like', 'an', 'illsheathed', 'knife']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hal_model = HALModel(window_size=2)\n",
        "hal_model.train(lines)"
      ],
      "metadata": {
        "id": "ft7swRUQrxRQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordsim_path = 'combined.csv'\n",
        "word_sim_data = pd.read_csv(wordsim_path)\n",
        "word_pairs = [(w1,w2) for w1,w2 in zip(word_sim_data['Word 1'], word_sim_data['Word 2'])]\n",
        "human_scores = word_sim_data['Human (mean)'].astype(float)"
      ],
      "metadata": {
        "id": "EE5z3Bkes88n"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_cross_validation(hal_model, lines, word_pairs, human_scores, k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYee4B_vrzcE",
        "outputId": "5664d612-d246-4b4f-e7da-6a21788970fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Spearman Correlation: 0.0231\n",
            "\n",
            "Fold 2\n",
            "Spearman Correlation: 0.0391\n",
            "\n",
            "Fold 3\n",
            "Spearman Correlation: 0.0103\n",
            "\n",
            "Fold 4\n",
            "Spearman Correlation: 0.0173\n",
            "\n",
            "Fold 5\n",
            "Spearman Correlation: 0.0215\n",
            "\n",
            "Fold 6\n",
            "Spearman Correlation: 0.0159\n",
            "\n",
            "Fold 7\n",
            "Spearman Correlation: 0.0206\n",
            "\n",
            "Fold 8\n",
            "Spearman Correlation: 0.0158\n",
            "\n",
            "Fold 9\n",
            "Spearman Correlation: 0.0290\n",
            "\n",
            "Fold 10\n",
            "Spearman Correlation: 0.0072\n",
            "\n",
            "Overall Average Spearman Correlation: 0.0200\n"
          ]
        }
      ]
    }
  ]
}